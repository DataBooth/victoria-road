{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from functools import cache, wraps\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import duckdb\n",
    "import folium\n",
    "import httpx\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_if_outdated(threshold_seconds):\n",
    "    def decorator(download_func):\n",
    "        @wraps(download_func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            extract_dir = Path(kwargs.get(\"extract_dir\", \"../data/road_traffic_counts_hourly_permanent\"))\n",
    "            # Ensure the directory exists\n",
    "            extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Check if the directory is not empty\n",
    "            if extract_dir.exists() and any(extract_dir.iterdir()):\n",
    "                now = time.time()\n",
    "\n",
    "                # Check the age of the first file in the directory\n",
    "                first_file = next(extract_dir.iterdir())\n",
    "                file_mod_time = os.path.getmtime(first_file)\n",
    "\n",
    "                # If the file is newer than the threshold, skip the download\n",
    "                if now - file_mod_time < threshold_seconds:\n",
    "                    print(\"Files are up-to-date. Skipping download.\")\n",
    "                    return [path.as_posix() for path in extract_dir.glob(\"*/*.csv\")]\n",
    "\n",
    "            # If the files are older than the threshold, or the directory is empty, call the download function\n",
    "            return download_func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_counts = \"road_traffic_counts\"\n",
    "table_name_stations = \"station_reference\"\n",
    "\n",
    "\n",
    "csv_files_path = \"../data/road_traffic_counts_hourly_permanent/\"\n",
    "\n",
    "# station_reference_csv = \"../data/road_traffic_counts_station_reference.csv\"\n",
    "\n",
    "hourly_road_count_zip = \"https://opendata.transport.nsw.gov.au/dataset/ef2b0bd2-db1e-48f3-9ea1-2bb9e6bc6504/resource/bca06c7e-30be-4a90-bc8b-c67428c0823a/download/road_traffic_counts_hourly_permanent.zip\"\n",
    "station_reference_csv = \"https://opendata.transport.nsw.gov.au/dataset/ef2b0bd2-db1e-48f3-9ea1-2bb9e6bc6504/resource/c65ad7b4-0257-4cc6-953e-5299ac8d27ba/download/road_traffic_counts_station_reference.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@download_if_outdated(threshold_seconds=2 * 24 * 60 * 60)  # 2 days in seconds\n",
    "def download_extract_hourly_road_count_data():\n",
    "    extract_dir = Path(csv_files_path)\n",
    "    extract_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with httpx.Client() as client:\n",
    "        response = client.get(hourly_road_count_zip)\n",
    "\n",
    "    with ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    return [path.as_posix() for path in extract_dir.glob(\"*/*.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = download_extract_hourly_road_count_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def load_data_duckdb():\n",
    "    con = duckdb.connect()\n",
    "\n",
    "    con.execute(\n",
    "        f\"CREATE TABLE {table_name_stations} AS SELECT * FROM read_csv_auto('{station_reference_csv}')\"\n",
    "    )\n",
    "\n",
    "    # Assume the first file defines the table structure\n",
    "    con.execute(f\"CREATE TABLE {table_name_counts} AS SELECT * FROM read_csv_auto('{csv_files[0]}')\")\n",
    "\n",
    "    # For each subsequent file, insert the data into the existing table\n",
    "    for csv_file in csv_files[1:]:\n",
    "        con.execute(f\"INSERT INTO {table_name_counts} SELECT * FROM read_csv_auto('{csv_file}')\")\n",
    "\n",
    "    df = con.sql(f\"SELECT * FROM {table_name_counts}\").to_df()\n",
    "    stats = pd.DataFrame(df.describe())\n",
    "    stats_all = pd.DataFrame(df.describe(include=\"all\"))\n",
    "\n",
    "    # stats_objects = df.describe(include=[object])\n",
    "    return df, stats, stats_all, con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, stats, stats_all, con = load_data_duckdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_schema(table_name):\n",
    "    schema = con.execute(f\"DESCRIBE {table_name}\").fetch_df()\n",
    "    return schema[[\"column_name\", \"column_type\", \"null\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_schema(table_name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_schema(table_name_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_station_id():\n",
    "    exclude_station_id = [\"18031\", \"11139\", \"19035\"]\n",
    "    exclude_station_id_sql = \", \".join(f\"'{id}'\" for id in exclude_station_id)\n",
    "\n",
    "    station_sql_query = f\"\"\"\n",
    "        SELECT * FROM {table_name_stations}\n",
    "        WHERE full_name ILIKE '%Victoria Road%'\n",
    "        AND station_id NOT IN ({exclude_station_id_sql});\n",
    "    \"\"\"\n",
    "\n",
    "    station_df = con.sql(station_sql_query).to_df()\n",
    "    return station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = df_station_id()\n",
    "vic_rd_stations = station_df[\"station_key\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = con.execute(f\"SELECT COUNT(*) FROM {table_name_counts}\").fetchone()\n",
    "\n",
    "# result now contains the count of rows, which is the first (and only) element in the returned tuple\n",
    "row_count = result[0]\n",
    "\n",
    "print(f\"Number of rows in {table_name_counts}: {row_count}\")\n",
    "assert len(df) == row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year_start to datetime\n",
    "year_start_datetime = pd.to_datetime(\"2018-01-01\")\n",
    "\n",
    "# Get the current date as datetime\n",
    "current_date_datetime = pd.to_datetime(\"now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_for_station_key_by_hour(station_key, hour, year_start=year_start_datetime):\n",
    "    df = con.sql(\n",
    "        f\"SELECT date, hour_{hour:02}, daily_total FROM {table_name_counts} WHERE station_key = {station_key} AND classification_seq = 2 ORDER BY date ASC\"\n",
    "    ).to_df()\n",
    "    quantile_max = round(df[f\"hour_{hour:02}\"].quantile(0.999) / 100) * 100  # round to nearest 100\n",
    "    df.plot(\n",
    "        x=\"date\", y=f\"hour_{hour:02}\", xlim=[year_start, current_date_datetime], ylim=[0, quantile_max]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = {}\n",
    "# quantiles = {}\n",
    "# for hour in range(0, 24):\n",
    "#     df_all[hour] = plot_counts_for_station_key_by_hour(\"99990010\", hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_hourly_count(df, year_start=year_start_datetime):\n",
    "    # Assuming df is your DataFrame and it contains a 'date' column and multiple 'hour_xx' columns\n",
    "\n",
    "    df_plot = df.copy()\n",
    "    df_plot = df_plot[df_plot[\"date\"] >= year_start]\n",
    "    # Create a figure with a slider\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Add traces for each hour, assuming hours 0 through 23\n",
    "    for hour in range(24):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df[\"date\"], y=df[f\"hour_{hour:02}\"], name=f\"Hour {hour}\"),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "    # Create and add slider\n",
    "    steps = []\n",
    "    for i, hour in enumerate(range(24)):\n",
    "        step = dict(method=\"update\", args=[{\"visible\": [False] * 24}], label=f\"Hour {hour}\")\n",
    "        step[\"args\"][0][\"visible\"][i] = True  # Toggle i-th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(active=0, currentvalue={\"prefix\": \"Hour: \"}, pad={\"t\": 50}, steps=steps)]\n",
    "\n",
    "    fig.update_layout(sliders=sliders)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotly_hourly_count()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_for_station_key(station_key):\n",
    "    # df = con.sql(f\"SELECT * FROM {table_name_counts} WHERE station_key = {station_key} ORDER BY date\").to_df()\n",
    "    df = con.sql(\n",
    "        f\"SELECT date, daily_total FROM {table_name_counts} WHERE station_key = {station_key} AND classification_seq = 2 ORDER BY date ASC\"\n",
    "    ).to_df()\n",
    "    if len(df) > 0:\n",
    "        df.plot(x=\"date\", y=\"daily_total\", legend=f\"Station key: {station_key}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Station key: {station_key} has no data\")\n",
    "        return station_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = {}\n",
    "station_key_no_data = []\n",
    "\n",
    "for station_key in vic_rd_stations:\n",
    "    result = plot_counts_for_station_key(station_key)\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        df_all[station_key] = result\n",
    "    else:\n",
    "        station_key_no_data.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_key_no_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([table_name[0] for table_name in con.execute(\"SHOW TABLES;\").fetchall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_selected_stations(station_df):\n",
    "    df = station_df.copy()\n",
    "    # Assuming df has 'wgs84_latitude', 'wgs84_longitude', 'station_id', 'station_key' and 'full_name' columns\n",
    "\n",
    "    m = folium.Map()\n",
    "    fg = folium.FeatureGroup()  # Create a feature group\n",
    "\n",
    "    # Add markers to the feature group with popups\n",
    "    for _, row in df.iterrows():\n",
    "        popup_text = f\"Station ID (Key): {row['station_id']} ({row['station_key']})<br>Full Name: {row['full_name']}\"\n",
    "        marker = folium.Marker(\n",
    "            [row[\"wgs84_latitude\"], row[\"wgs84_longitude\"]],\n",
    "            popup=folium.Popup(popup_text, max_width=450),\n",
    "        )\n",
    "        fg.add_child(marker)\n",
    "    m.add_child(fg)\n",
    "    m.fit_bounds(fg.get_bounds())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = map_selected_stations(station_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
